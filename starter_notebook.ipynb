{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Building Time Series Forecasts\n",
    "\n",
    "**Student Name:** [Your Name Here]\n",
    "\n",
    "**Date:** [Date]\n",
    "\n",
    "---\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "In this assignment, you'll analyze temporal data from Corporación Favorita stores to identify trends, seasonality, and anomalies, then build forecasting models using decomposition techniques. You'll work with real retail sales data to predict future sales patterns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by downloading all the of the necessary libraries for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib seaborn scikit-learn statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# For time series analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, load the training, store, and holiday CSV data from the `data` directory using `pd.read_csv()`. Display basic information about the training data and print out the first few rows to get an understanding of what the training data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "# TODO: Load all three required CSV files\n",
    "train_df = None  # Replace with pd.read_csv('data/train.csv')\n",
    "holidays_df = None  # Replace with pd.read_csv('data/holidays_events.csv')\n",
    "stores_df = None  # Replace with pd.read_csv('data/stores.csv')\n",
    "\n",
    "# Display basic information\n",
    "if train_df is not None:\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Date range: {train_df['date'].min()} to {train_df['date'].max()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    # TODO: Display the first few rows\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKPOINT: Verify datasets loaded correctly\")\n",
    "print(f\"Train data shape: {train_df.shape if train_df is not None else 'Not loaded'}\")\n",
    "print(f\"Holidays data shape: {holidays_df.shape if holidays_df is not None else 'Not loaded'}\")\n",
    "print(f\"Stores data shape: {stores_df.shape if stores_df is not None else 'Not loaded'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Available Stores and Product Families\n",
    "Display store information from `stores_df` to help choose a store. Consider looking at store type, cluster, and city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data to help choose your store and products\n",
    "if train_df is not None:\n",
    "    print(\"Available stores:\")\n",
    "    print(f\"Total number of stores: {train_df['store_nbr'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nAvailable product families:\")\n",
    "    families = train_df['family'].value_counts().head(20)\n",
    "    print(families)\n",
    "    \n",
    "    # TODO: Display store information from stores_df to help choose a store\n",
    "    # Consider looking at store type, cluster, and city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Select and Prepare Your Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Your Store and Product Families\n",
    "\n",
    "Choose one store and two contrasting product families. Good contrasts might be:\n",
    "- PRODUCE vs BEVERAGES (perishable vs non-perishable)\n",
    "- BREAD/BAKERY vs AUTOMOTIVE (daily necessity vs occasional purchase)\n",
    "- GROCERY I vs CELEBRATION (staples vs seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select your store and product families\n",
    "selected_store = None  # Replace with your chosen store number (e.g., 1)\n",
    "product_family_1 = None  # Replace with first product family (e.g., 'PRODUCE')\n",
    "product_family_2 = None  # Replace with second product family (e.g., 'BEVERAGES')\n",
    "\n",
    "print(f\"Selected Store: {selected_store}\")\n",
    "print(f\"Product Family 1: {product_family_1}\")\n",
    "print(f\"Product Family 2: {product_family_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data\n",
    "Filter the `train_df` data to your selected store and products. Create a date range from 2016-01-01 to 2017-08-15 for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Filter train_df for selected store and date range 2016-01-01 to 2017-08-15\n",
    "\n",
    "# Convert date column to datetime if needed\n",
    "if train_df is not None:\n",
    "    train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "\n",
    "# Filter for date range\n",
    "start_date = '2016-01-01'\n",
    "end_date = '2017-08-15'\n",
    "\n",
    "# TODO: Create filtered datasets for each product family\n",
    "product1_data = None  # Filter for store, product_family_1, and date range\n",
    "product2_data = None  # Filter for store, product_family_2, and date range\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKPOINT: Data filtered successfully\")\n",
    "print(f\"Product 1 data shape: {product1_data.shape if product1_data is not None else 'Not filtered'}\")\n",
    "print(f\"Product 2 data shape: {product2_data.shape if product2_data is not None else 'Not filtered'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Daily Sales\n",
    "Aggregate daily sales and handle missing dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Group by date and sum sales for each product family\n",
    "# TODO: Create a complete date range and fill missing dates with 0 sales\n",
    "\n",
    "# Example structure (replace with your implementation):\n",
    "# date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "# product1_ts = product1_data.groupby('date')['sales'].sum().reindex(date_range, fill_value=0)\n",
    "\n",
    "product1_ts = None  # Replace with time series for product 1\n",
    "product2_ts = None  # Replace with time series for product 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Raw Time Series\n",
    "Plot both time series to see the raw patterns using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize both time series\n",
    "# TODO: Create a figure with 2 subplots showing both time series\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot Product 1\n",
    "# TODO: Plot product1_ts on axes[0]\n",
    "\n",
    "# Plot Product 2\n",
    "# TODO: Plot product2_ts on axes[1]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: What patterns do you see in the raw data?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Your Choice (2-3 sentences)\n",
    "Explain why you chose these specific products. \n",
    "- What contrasts do they represent? \n",
    "- Why will they be interesting to compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ REPLACE WITH YOUR JUSTIFICATION ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Identify Trends Using Moving Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Moving Averages\n",
    "Calculate the 7-day and 30-day moving averages for both products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate 7-day and 30-day moving averages for both products\n",
    "\n",
    "# For Product 1\n",
    "product1_ma7 = None  # Replace with product1_ts.rolling(window=7).mean()\n",
    "product1_ma30 = None  # Replace with product1_ts.rolling(window=30).mean()\n",
    "\n",
    "# For Product 2\n",
    "product2_ma7 = None  # Replace with product2_ts.rolling(window=7).mean()\n",
    "product2_ma30 = None  # Replace with product2_ts.rolling(window=30).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Original Sales\n",
    "Using matplotlip, plot original sales with both moving averages (7-day and 30-day) overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original sales with moving averages\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Product 1\n",
    "# TODO: Plot original, 7-day MA, and 30-day MA for product 1\n",
    "# axes[0].plot(product1_ts.index, product1_ts.values, alpha=0.4, label='Daily Sales')\n",
    "# axes[0].plot(product1_ma7.index, product1_ma7.values, label='7-Day MA')\n",
    "# axes[0].plot(product1_ma30.index, product1_ma30.values, label='30-Day MA')\n",
    "\n",
    "# Product 2\n",
    "# TODO: Plot original, 7-day MA, and 30-day MA for product 2\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Explain Trend Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the data with `holidays_events.csv` to explain what caused these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with holidays to explain trend changes\n",
    "# TODO: Convert holidays_df date to datetime and filter for your date range\n",
    "if holidays_df is not None:\n",
    "    holidays_df['date'] = pd.to_datetime(holidays_df['date'])\n",
    "    relevant_holidays = None  # Filter holidays_df for your date range\n",
    "    \n",
    "    # TODO: Display holidays that might explain trend changes\n",
    "    print(\"Key holidays/events in the period:\")\n",
    "    # Display relevant holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Trend Analysis\n",
    "For each product family, document:\n",
    "1. Overall trend direction (growing, declining, stable)\n",
    "2. Any trend changes that correlate with holidays or events\n",
    "3. Business implications of the trends you discovered\n",
    "\n",
    "Update the markdown cell below with your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Product 1 Trends:**\n",
    "- Overall trend direction: [ Growing/Declining/Stable? ]\n",
    "- Key trend changes: [ List at least 3 significant changes and dates ]\n",
    "- Holiday correlations: [ Which holidays affected sales? ]\n",
    "- Business implications: [ What do these trends mean for inventory ]\n",
    "\n",
    "**Product 2 Trends:**\n",
    "- Overall trend direction: [ Growing/Declining/Stable? ]\n",
    "- Key trend changes: [ List at least 3 significant changes and dates ]\n",
    "- Holiday correlations: [ Which holidays affected sales? ]\n",
    "- Business implications: [ What do these trends mean for inventory ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Detect and Visualize Seasonal Patterns\n",
    "\n",
    "Analyze the seasonal components of your sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day-of-Week Analysis\n",
    "\n",
    "Add day of week to your data and calculate the average sales by day. Create a bar plot to visualize the weekday patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze day-of-week patterns\n",
    "# TODO: Add day of week to your data and calculate average sales by day\n",
    "\n",
    "# For Product 1\n",
    "product1_dow = None  # Create DataFrame with date and sales\n",
    "# Add day of week: product1_dow['day_of_week'] = product1_dow.index.day_name()\n",
    "# Group by day of week and calculate mean sales\n",
    "\n",
    "# For Product 2\n",
    "product2_dow = None  # Similar for product 2\n",
    "\n",
    "# Create bar plot comparing weekday patterns\n",
    "# TODO: Create side-by-side bar plot showing average sales by day of week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Seasonality Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average sales by month for both products. Once calculated, create a line plot showing monthly patterns for both products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze monthly patterns\n",
    "# TODO: Calculate average sales by month for both products\n",
    "\n",
    "# For Product 1\n",
    "product1_monthly = None  # Group by month and calculate mean sales\n",
    "\n",
    "# For Product 2  \n",
    "product2_monthly = None  # Group by month and calculate mean sales\n",
    "\n",
    "# Create visualization\n",
    "# TODO: Create line plot showing monthly patterns for both products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Impact Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the average sales on holidays compared to regular days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze holiday vs non-holiday sales\n",
    "# TODO: Compare average sales on holidays vs regular days\n",
    "\n",
    "# Create a list of holiday dates\n",
    "holiday_dates = None  # Extract unique dates from holidays_df\n",
    "\n",
    "# Calculate average sales on holidays vs non-holidays for both products\n",
    "# TODO: Split data into holiday and non-holiday sales and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Pattern Findings\n",
    "\n",
    "**Document your findings:**\n",
    "- Which days of the week have highest/lowest sales?\n",
    "- Are there monthly patterns (e.g., payday effects)?\n",
    "- How do holidays affect each product differently?\n",
    "- What business decisions could these patterns inform?\n",
    "\n",
    "Update the markdown cell below with your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ Write your analysis here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Decompose Time Series and Build Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition\n",
    "# TODO: Use seasonal_decompose to separate trend, seasonal, and residual components\n",
    "\n",
    "# For Product 1\n",
    "decomposition1 = None  # seasonal_decompose(product1_ts, model='additive', period=7)\n",
    "\n",
    "# For Product 2\n",
    "decomposition2 = None  # seasonal_decompose(product2_ts, model='additive', period=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decomposition for Product 1\n",
    "if decomposition1 is not None:\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "    \n",
    "    # TODO: Plot each component\n",
    "    # decomposition1.observed.plot(ax=axes[0], title=f'{product_family_1} - Original')\n",
    "    # decomposition1.trend.plot(ax=axes[1], title='Trend')\n",
    "    # decomposition1.seasonal.plot(ax=axes[2], title='Seasonal')\n",
    "    # decomposition1.resid.plot(ax=axes[3], title='Residual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decomposition for Product 2\n",
    "# TODO: Similar visualization for Product 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Forecasts Using Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for validation\n",
    "# Use last 30 days as test set\n",
    "test_days = 30\n",
    "\n",
    "# For Product 1\n",
    "train1 = None  # product1_ts[:-test_days]\n",
    "test1 = None  # product1_ts[-test_days:]\n",
    "\n",
    "# For Product 2\n",
    "train2 = None  # product2_ts[:-test_days]\n",
    "test2 = None  # product2_ts[-test_days:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline forecast (naive method - use average of last 30 days)\n",
    "# TODO: Calculate baseline forecasts\n",
    "\n",
    "# For Product 1\n",
    "baseline_forecast1 = None  # np.repeat(train1[-30:].mean(), test_days)\n",
    "\n",
    "# For Product 2\n",
    "baseline_forecast2 = None  # np.repeat(train2[-30:].mean(), test_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decomposition-based forecast\n",
    "# TODO: Use the decomposition components to build a forecast\n",
    "# Simple approach: extend trend + repeat seasonal pattern\n",
    "\n",
    "# For Product 1\n",
    "# 1. Extend trend (use last trend value or simple linear extension)\n",
    "# 2. Repeat seasonal pattern for next 30 days\n",
    "# 3. Combine trend + seasonal\n",
    "decomp_forecast1 = None  # Your decomposition-based forecast\n",
    "\n",
    "# For Product 2\n",
    "decomp_forecast2 = None  # Your decomposition-based forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Forecast Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE for both methods\n",
    "# TODO: Calculate RMSE for baseline and decomposition forecasts\n",
    "\n",
    "# Product 1\n",
    "baseline_rmse1 = None  # np.sqrt(mean_squared_error(test1, baseline_forecast1))\n",
    "decomp_rmse1 = None  # np.sqrt(mean_squared_error(test1, decomp_forecast1))\n",
    "\n",
    "# Product 2\n",
    "baseline_rmse2 = None  # np.sqrt(mean_squared_error(test2, baseline_forecast2))\n",
    "decomp_rmse2 = None  # np.sqrt(mean_squared_error(test2, decomp_forecast2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Product': [product_family_1, product_family_1, product_family_2, product_family_2],\n",
    "    'Method': ['Baseline', 'Decomposition', 'Baseline', 'Decomposition'],\n",
    "    'RMSE': [baseline_rmse1, decomp_rmse1, baseline_rmse2, decomp_rmse2]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# TODO: Calculate percentage improvement\n",
    "# Add improvement column to comparison_df\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FORECAST PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "# TODO: Display comparison table\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs forecasted values\n",
    "# TODO: Create visualization showing:\n",
    "# - Historical data (train)\n",
    "# - Actual test data\n",
    "# - Baseline forecast\n",
    "# - Decomposition forecast\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Product 1 forecast visualization\n",
    "# TODO: Plot on axes[0]\n",
    "\n",
    "# Product 2 forecast visualization  \n",
    "# TODO: Plot on axes[1]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Generate Business Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executive Summary (200-300 words)\n",
    "\n",
    "Based on your analysis, write a brief executive summary that includes:\n",
    "- **Key Patterns Discovered:** Summarize the main trends and seasonal patterns for each product\n",
    "- **Inventory Planning Recommendations:** Specific recommendations based on your findings\n",
    "- **High-Risk Periods:** Identify periods requiring special attention\n",
    "- **Predictability Analysis:** Which product is more predictable and why?\n",
    "- **Specific Action Item:** One concrete action the store manager should take based on your forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ Write your 200 to 300 word executive summary here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Submit Your Work\n",
    "\n",
    "Before submitting:\n",
    "1. Ensure all code cells run without errors\n",
    "2. Verify all visualizations display correctly\n",
    "3. Check that your analysis sections are complete\n",
    "4. Review your executive summary\n",
    "\n",
    "Push to GitHub:\n",
    "```bash\n",
    "git add .\n",
    "git commit -m 'completed time series forecasting assignment'\n",
    "git push\n",
    "```\n",
    "\n",
    "Submit your GitHub repository link on the course platform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
